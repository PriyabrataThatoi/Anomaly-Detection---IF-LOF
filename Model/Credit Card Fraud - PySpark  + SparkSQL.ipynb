{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.stat import Correlation\n",
    "import math\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark context and SQL context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform.startswith('win'):\n",
    "    os.chdir(r\"C:\\Users\\Thatoi\\SparkPythonDoBigDataAnalytics-Resources\\SparkPythonDoBigDataAnalytics-Resources\")\n",
    "    os.environ['SPARK_HOME'] = 'C:/Users/Thatoi/Downloads/spark-3.0.0-preview2-bin-hadoop2.7'\n",
    "# create a variable for root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME'] \n",
    "\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Spark Session\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"V2 Maestros\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///c:/Users/temp/spark-warehouse\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Get the Spark Context from Spark Session    \n",
    "SpContext = SpSession.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting a SQL context\n",
    "sql = pyspark.SQLContext(SpContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0-preview2\n"
     ]
    }
   ],
   "source": [
    "print(SpContext.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data ingestion and preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining own schema\n",
    "#This is done so that there would not be\n",
    "#any conflict between datatypes\n",
    "dataschema = [StructField('CustomerId', IntegerType(), True),\n",
    "              StructField('Balance_limit', IntegerType(), True),\n",
    "              StructField('Sex', StringType(), True),\n",
    "              StructField('Education', StringType(), True),\n",
    "              StructField('Marriage', StringType(), True),\n",
    "              StructField('Age', IntegerType(), True),\n",
    "              StructField('Pay1', IntegerType(), True),\n",
    "              StructField('Pay2', IntegerType(), True),\n",
    "              StructField('Pay3', IntegerType(), True),\n",
    "              StructField('Pay4', IntegerType(), True),\n",
    "              StructField('Pay5', IntegerType(), True),\n",
    "              StructField('Pay6', IntegerType(), True),\n",
    "              StructField('BillAmount1', IntegerType(), True),\n",
    "              StructField('BillAmount2', IntegerType(), True),\n",
    "              StructField('BillAmount3', IntegerType(), True),\n",
    "              StructField('BillAmount4', IntegerType(), True),\n",
    "              StructField('BillAmount5', IntegerType(), True),\n",
    "              StructField('BillAmount6', IntegerType(), True),\n",
    "              StructField('PayAmount1', IntegerType(), True),\n",
    "              StructField('PayAmount2', IntegerType(), True),\n",
    "              StructField('PayAmount3', IntegerType(), True),\n",
    "              StructField('PayAmount4', IntegerType(), True),\n",
    "              StructField('PayAmount5', IntegerType(), True),\n",
    "              StructField('PayAmount6', IntegerType(), True),\n",
    "              StructField('Defaulted', StringType(), True),\n",
    "             ]\n",
    "finalstructure = StructType(dataschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Balance_limit: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Education: string (nullable = true)\n",
      " |-- Marriage: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Pay1: integer (nullable = true)\n",
      " |-- Pay2: integer (nullable = true)\n",
      " |-- Pay3: integer (nullable = true)\n",
      " |-- Pay4: integer (nullable = true)\n",
      " |-- Pay5: integer (nullable = true)\n",
      " |-- Pay6: integer (nullable = true)\n",
      " |-- BillAmount1: integer (nullable = true)\n",
      " |-- BillAmount2: integer (nullable = true)\n",
      " |-- BillAmount3: integer (nullable = true)\n",
      " |-- BillAmount4: integer (nullable = true)\n",
      " |-- BillAmount5: integer (nullable = true)\n",
      " |-- BillAmount6: integer (nullable = true)\n",
      " |-- PayAmount1: integer (nullable = true)\n",
      " |-- PayAmount2: integer (nullable = true)\n",
      " |-- PayAmount3: integer (nullable = true)\n",
      " |-- PayAmount4: integer (nullable = true)\n",
      " |-- PayAmount5: integer (nullable = true)\n",
      " |-- PayAmount6: integer (nullable = true)\n",
      " |-- Defaulted: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading csv file into spark dataframe using our schema \n",
    "df = sql.read.csv('credit-card-default-1000.csv', header = True,schema = finalstructure,mode=\"DROPMALFORMED\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---------+--------+---+---------+\n",
      "|CustomerId|Sex|Education|Marriage|Age|Defaulted|\n",
      "+----------+---+---------+--------+---+---------+\n",
      "|       530|  2|        2|       2| 21|        0|\n",
      "|        38|  2|        2|       2| 22|        0|\n",
      "|        43|  1|        2|       2| 22|        0|\n",
      "|        47|  2|        1|       2| 22|        0|\n",
      "|        70|  1|        4|       2| 22|        0|\n",
      "|        79|  2|        2|       2| 22|        0|\n",
      "|        99|  F|        3|       1| 22|        0|\n",
      "|       104|  2|        3|       2| 22|        0|\n",
      "|       135|  2|        2|       2| 22|        0|\n",
      "|       170|  2|        2|       2| 22|        0|\n",
      "+----------+---+---------+--------+---+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analyzing categorical variables\n",
    "df.select('CustomerId','Sex','Education','Marriage','Age','Defaulted').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "| Sex|count(Defaulted)|\n",
      "+----+----------------+\n",
      "|   2|             338|\n",
      "|   1|             252|\n",
      "|   F|             253|\n",
      "|   M|             157|\n",
      "|null|               2|\n",
      "+----+----------------+\n",
      "\n",
      "+---------+----------------+\n",
      "|Education|count(Defaulted)|\n",
      "+---------+----------------+\n",
      "|        2|             448|\n",
      "|        1|             395|\n",
      "|        4|               7|\n",
      "|        3|             150|\n",
      "|     null|               2|\n",
      "+---------+----------------+\n",
      "\n",
      "+--------+----------------+\n",
      "|Marriage|count(Defaulted)|\n",
      "+--------+----------------+\n",
      "|       2|             570|\n",
      "|       1|             411|\n",
      "|       3|              19|\n",
      "|    null|               2|\n",
      "+--------+----------------+\n",
      "\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "#Number of sex,education,marriage categories\n",
    "print(df.groupby('Sex').agg(func.count('Defaulted')).show(),\n",
    "      df.groupby('Education').agg(func.count('Defaulted')).show(),\n",
    "      df.groupby('Marriage').agg(func.count('Defaulted')).show())\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "|Sex|count(Defaulted)|\n",
      "+---+----------------+\n",
      "|  2|             338|\n",
      "|  1|             254|\n",
      "|  F|             253|\n",
      "|  M|             157|\n",
      "+---+----------------+\n",
      "\n",
      "+---------+----------------+\n",
      "|Education|count(Defaulted)|\n",
      "+---------+----------------+\n",
      "|        2|             448|\n",
      "|        1|             395|\n",
      "|        4|               9|\n",
      "|        3|             150|\n",
      "+---------+----------------+\n",
      "\n",
      "+--------+----------------+\n",
      "|Marriage|count(Defaulted)|\n",
      "+--------+----------------+\n",
      "|       2|             570|\n",
      "|       1|             411|\n",
      "|       3|              21|\n",
      "+--------+----------------+\n",
      "\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "#handelling null values\n",
    "df1=df.na.fill('1','Sex').na.fill('4','Education').na.fill('3','Marriage')\n",
    "print(df1.groupby('Sex').agg(func.count('Defaulted')).show(),\n",
    "      df1.groupby('Education').agg(func.count('Defaulted')).show(),\n",
    "      df1.groupby('Marriage').agg(func.count('Defaulted')).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "|Sex|count(Defaulted)|\n",
      "+---+----------------+\n",
      "|  2|             749|\n",
      "|  1|             253|\n",
      "+---+----------------+\n",
      "\n",
      "+---------+----------------+\n",
      "|Education|count(Defaulted)|\n",
      "+---------+----------------+\n",
      "|        2|             448|\n",
      "|        1|             395|\n",
      "|        4|               9|\n",
      "|        3|             150|\n",
      "+---------+----------------+\n",
      "\n",
      "+--------+----------------+\n",
      "|Marriage|count(Defaulted)|\n",
      "+--------+----------------+\n",
      "|       2|             570|\n",
      "|       1|             432|\n",
      "+--------+----------------+\n",
      "\n",
      "None None None\n"
     ]
    }
   ],
   "source": [
    "#Manipulating data using withColumn & spark sql functions\n",
    "#df1.map()\n",
    "df2=df1.withColumn(\"Sex\", func.when(func.col(\"Sex\")=='F', '1').otherwise('2'))\n",
    "df3=df2.withColumn(\"Marriage\", func.when(func.col(\"Marriage\")=='3', '1').otherwise(func.col(\"Marriage\")))\n",
    "print(df3.groupby('Sex').agg(func.count('Defaulted')).show(),\n",
    "      df3.groupby('Education').agg(func.count('Defaulted')).show(),\n",
    "      df3.groupby('Marriage').agg(func.count('Defaulted')).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---------+--------+\n",
      "|CustomerId|Sex|Education|Marriage|\n",
      "+----------+---+---------+--------+\n",
      "|       530|  2|        2|       2|\n",
      "|        38|  2|        2|       2|\n",
      "|        43|  2|        2|       2|\n",
      "|        47|  2|        1|       2|\n",
      "|        70|  2|        4|       2|\n",
      "|        79|  2|        2|       2|\n",
      "|        99|  1|        3|       1|\n",
      "|       104|  2|        3|       2|\n",
      "|       135|  2|        2|       2|\n",
      "|       170|  2|        2|       2|\n",
      "+----------+---+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.createOrReplaceTempView(\"events\")\n",
    "sql.sql(\"\"\"SELECT CustomerId,\n",
    "                  Sex,\n",
    "                  Education,\n",
    "                  Marriage\n",
    "                  FROM events \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---------+--------+---+-------------------+------------------+------------------+---------+\n",
      "|CustomerId|Sex|Education|Marriage|Age|        Average_Pay| AverageBillAmount|  AveragePayAmount|Defaulted|\n",
      "+----------+---+---------+--------+---+-------------------+------------------+------------------+---------+\n",
      "|       530|  2|        2|       2| 21|-0.3333333333333333|               0.0|           27000.0|        0|\n",
      "|        38|  2|        2|       2| 22|-0.6666666666666666|               0.0| 262.6666666666667|        0|\n",
      "|        43|  2|        2|       2| 22|-0.6666666666666666|               0.0|             250.0|        0|\n",
      "|        47|  2|        1|       2| 22|                0.0|             431.0|21969.166666666668|        0|\n",
      "|        70|  2|        4|       2| 22|                0.0|            3349.5|           28651.5|        0|\n",
      "|        79|  2|        2|       2| 22|-0.6666666666666666|1025.3333333333333|            7358.0|        0|\n",
      "|        99|  1|        3|       1| 22|-0.3333333333333333|117.83333333333333|             829.5|        0|\n",
      "|       104|  2|        3|       2| 22|-0.3333333333333333| 473.3333333333333|3328.3333333333335|        0|\n",
      "|       135|  2|        2|       2| 22|-0.6666666666666666|61.333333333333336| 359.8333333333333|        0|\n",
      "|       170|  2|        2|       2| 22|0.16666666666666666|1316.8333333333333|            6896.5|        0|\n",
      "+----------+---+---------+--------+---+-------------------+------------------+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Average Pay, BillAmount and PayAmount\n",
    "marksColumns1 = [col('Pay1'),col('Pay2'),col('Pay3'),col('Pay4'),col('Pay5'),col('Pay6')]\n",
    "marksColumns2 = [col('BillAmount1'),col('BillAmount2'),col('BillAmount3'),col('BillAmount4'),col('BillAmount5'),col('BillAmount6')]\n",
    "marksColumns3 = [col('PayAmount1'),col('PayAmount2'),col('PayAmount3'),col('PayAmount4'),col('PayAmount5'),col('PayAmount6')]\n",
    "averageFunc1 = sum(x for x in marksColumns1)/len(marksColumns1)\n",
    "averageFunc2 = sum(x for x in marksColumns2)/len(marksColumns2)\n",
    "averageFunc3 = sum(x for x in marksColumns3)/len(marksColumns3)\n",
    "df4 = df3.withColumn('Average_Pay', averageFunc1).withColumn('AverageBillAmount',averageFunc2).withColumn('AveragePayAmount',averageFunc3)\n",
    "df4.select('CustomerId','Sex','Education','Marriage','Age','Average_Pay','AverageBillAmount','AveragePayAmount','Defaulted').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Balance_limit: integer (nullable = true)\n",
      " |-- Sex: string (nullable = false)\n",
      " |-- Education: string (nullable = false)\n",
      " |-- Marriage: string (nullable = false)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Pay1: integer (nullable = true)\n",
      " |-- Pay2: integer (nullable = true)\n",
      " |-- Pay3: integer (nullable = true)\n",
      " |-- Pay4: integer (nullable = true)\n",
      " |-- Pay5: integer (nullable = true)\n",
      " |-- Pay6: integer (nullable = true)\n",
      " |-- BillAmount1: integer (nullable = true)\n",
      " |-- BillAmount2: integer (nullable = true)\n",
      " |-- BillAmount3: integer (nullable = true)\n",
      " |-- BillAmount4: integer (nullable = true)\n",
      " |-- BillAmount5: integer (nullable = true)\n",
      " |-- BillAmount6: integer (nullable = true)\n",
      " |-- PayAmount1: integer (nullable = true)\n",
      " |-- PayAmount2: integer (nullable = true)\n",
      " |-- PayAmount3: integer (nullable = true)\n",
      " |-- PayAmount4: integer (nullable = true)\n",
      " |-- PayAmount5: integer (nullable = true)\n",
      " |-- PayAmount6: integer (nullable = true)\n",
      " |-- Defaulted: string (nullable = true)\n",
      " |-- Average_Pay: double (nullable = true)\n",
      " |-- AverageBillAmount: double (nullable = true)\n",
      " |-- AveragePayAmount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------+-----------+\n",
      "|Sex|Total|Defaults|PER_DEFAULT|\n",
      "+---+-----+--------+-----------+\n",
      "|  2|  749|   281.0|       38.0|\n",
      "|  1|  253|   122.0|       48.0|\n",
      "+---+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many defaulted in each of the gender type?\n",
    "df4.createOrReplaceTempView(\"data\")\n",
    "sql.sql(\"SELECT Sex, count(*) as Total, \" + \\\n",
    "                \" SUM(Defaulted) as Defaults, \" + \\\n",
    "                \" ROUND(SUM(Defaulted) * 100 / count(*)) as PER_DEFAULT \" + \\\n",
    "                \"FROM data GROUP BY Sex\"  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----+--------+-----------+\n",
      "|Marriage|Education|Total|Defaults|PER_DEFAULT|\n",
      "+--------+---------+-----+--------+-----------+\n",
      "|       1|        1|  127|    75.0|       59.0|\n",
      "|       1|        2|  205|   108.0|       53.0|\n",
      "|       1|        3|   95|    58.0|       61.0|\n",
      "|       1|        4|    5|     2.0|       40.0|\n",
      "|       2|        1|  268|    69.0|       26.0|\n",
      "|       2|        2|  243|    65.0|       27.0|\n",
      "|       2|        3|   55|    24.0|       44.0|\n",
      "|       2|        4|    4|     2.0|       50.0|\n",
      "+--------+---------+-----+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For each marriage & Education type, \n",
    "#What is the % of default ?\n",
    "sql.sql(\"SELECT Marriage, Education, count(*) as Total,\" + \\\n",
    "                \" SUM(Defaulted) as Defaults, \" + \\\n",
    "                \" ROUND(SUM(Defaulted) * 100 / count(*)) as PER_DEFAULT \" + \\\n",
    "                \"FROM data GROUP BY Marriage,Education \" + \\\n",
    "                \"ORDER BY 1,2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------+-----+------------------+------------------+\n",
      "|Marriage|Education|If_Defaulted|Total|  AveragePayAmount| AverageBillAmount|\n",
      "+--------+---------+------------+-----+------------------+------------------+\n",
      "|       1|        2|           0|   97| 4754.037800687283|45614.134020618556|\n",
      "|       1|        2|           1|  108| 2969.123456790124| 59826.90586419753|\n",
      "|       1|        3|           1|   58|1912.8620689655168|  52528.4252873563|\n",
      "|       1|        3|           0|   37|  4501.81981981982| 76919.13063063064|\n",
      "|       1|        1|           1|   75| 3680.115555555555|          70117.02|\n",
      "|       1|        1|           0|   52|3280.7916666666665| 53105.48717948718|\n",
      "|       1|        4|           0|    3|2489.1666666666665|           63433.0|\n",
      "|       1|        4|           1|    2|            1880.0|49100.583333333336|\n",
      "|       2|        2|           0|  178| 7049.232209737827| 21216.78838951311|\n",
      "|       2|        1|           0|  199| 6852.094639865995| 22938.27889447235|\n",
      "|       2|        3|           0|   31| 5735.596774193547|45419.145161290326|\n",
      "|       2|        4|           1|    2| 7599.583333333334| 217559.6666666667|\n",
      "|       2|        4|           0|    2|21186.583333333332| 8504.916666666668|\n",
      "|       2|        3|           1|   24|1650.7152777777776|           38906.5|\n",
      "|       2|        1|           1|   69| 3958.654589371981|54309.463768115944|\n",
      "|       2|        2|           1|   65| 3699.025641025642|  53161.2717948718|\n",
      "+--------+---------+------------+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For each Marriage, Education and Default type\n",
    "#What is the Average Pay and Bill Amount?\n",
    "SpSession.sql(\"SELECT Marriage, Education, Defaulted as If_Defaulted, count(*) as Total, \" + \\\n",
    "                \" AVG(AveragePayAmount) as AveragePayAmount, \" + \\\n",
    "                \" AVG(AverageBillAmount) as AverageBillAmount\" +\\\n",
    "                \" FROM data GROUP BY Marriage, Education, Defaulted ORDER BY 1\"  ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vector Assembler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to vector column first\n",
    "def transformToLabeledPoint(row) :\n",
    "    lp = ( row[\"Defaulted\"], \\\n",
    "            Vectors.dense([\n",
    "                row[\"Age\"], \\\n",
    "                row[\"AverageBillAmount\"], \\\n",
    "                row[\"AveragePayAmount\"], \\\n",
    "                row[\"Average_Pay\"], \\\n",
    "                row[\"Education\"], \\\n",
    "                row[\"Balance_limit\"], \\\n",
    "                row[\"Marriage\"], \\\n",
    "                row[\"Education\"], \\\n",
    "                row[\"Sex\"]\n",
    "        ]))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[21.0,0.0,27000.0...|\n",
      "|    0|[22.0,0.0,262.666...|\n",
      "|    0|[22.0,0.0,250.0,-...|\n",
      "|    0|[22.0,431.0,21969...|\n",
      "|    0|[22.0,3349.5,2865...|\n",
      "|    0|[22.0,1025.333333...|\n",
      "|    0|[22.0,117.8333333...|\n",
      "|    0|[22.0,473.3333333...|\n",
      "|    0|[22.0,61.33333333...|\n",
      "|    0|[22.0,1316.833333...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: string, features: vector]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccLp = df4.rdd.repartition(2).map(transformToLabeledPoint)\n",
    "ccLp.collect()\n",
    "ccNormDf = SpSession.createDataFrame(ccLp,[\"label\", \"features\"])\n",
    "ccNormDf.select(\"label\",\"features\").show(10)\n",
    "ccNormDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|       features_norm|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[21.0,0.0,27000.0...|[4.46529825357223...|\n",
      "|    0|[22.0,0.0,262.666...|[3.64882795223352...|\n",
      "|    0|[22.0,0.0,250.0,-...|[0.00213993904416...|\n",
      "|    0|[22.0,431.0,21969...|[5.18523465150902...|\n",
      "|    0|[22.0,3349.5,2865...|[4.22792351302008...|\n",
      "|    0|[22.0,1025.333333...|[5.72707866923517...|\n",
      "|    0|[22.0,117.8333333...|[4.31561533481982...|\n",
      "|    0|[22.0,473.3333333...|[4.08663669799754...|\n",
      "|    0|[22.0,61.33333333...|[7.22452397502066...|\n",
      "|    0|[22.0,1316.833333...|[3.77724552954406...|\n",
      "|    0|[22.0,693.6666666...|[6.75672217075056...|\n",
      "|    0|[22.0,1638.666666...|[6.15344453042691...|\n",
      "|    0|[22.0,592.5,1259....|[0.00185148820377...|\n",
      "|    0|[22.0,9743.333333...|[2.75434957704040...|\n",
      "|    0|[22.0,42.83333333...|[0.00109140518417...|\n",
      "|    0|[22.0,10246.66666...|[1.99520546081688...|\n",
      "|    0|[22.0,34142.83333...|[1.47889548914468...|\n",
      "|    0|[22.0,389.3333333...|[4.30292598967297...|\n",
      "|    0|[23.0,505.5,837.1...|[2.26881886605090...|\n",
      "|    0|[23.0,5379.833333...|[3.57677892914349...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalizing features\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "l1NormData = normalizer.transform(ccNormDf)\n",
    "l1NormData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partitioning and Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689 311\n"
     ]
    }
   ],
   "source": [
    "#Indexing needed as pre-req for Decision Trees\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(l1NormData)\n",
    "td = si_model.transform(l1NormData)\n",
    "td.collect()\n",
    "\n",
    "#Split into training and testing data\n",
    "(trainingData, testData) = td.randomSplit([0.7, 0.3])\n",
    "print(trainingData.count(),\n",
    "testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Decision Trees :  0.6945337620578779\n",
      "Results of Random Forest :  0.7395498392282959\n",
      "Results of Gradient Boost :  0.6913183279742765\n",
      "Results of Logistic regression :  0.729903536977492\n",
      "Results of Linear SVC :  0.6430868167202572\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \\\n",
    "                    labelCol=\"indexed\",metricName=\"accuracy\")\n",
    "\n",
    "#Create the Decision Trees model\n",
    "dtClassifer = DecisionTreeClassifier(labelCol=\"indexed\", \\\n",
    "                featuresCol=\"features_norm\")\n",
    "dtModel = dtClassifer.fit(trainingData)\n",
    "#Predict on the test data\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features_norm\").collect()\n",
    "print(\"Results of Decision Trees : \",evaluator.evaluate(predictions))      \n",
    "\n",
    "#Create the Random Forest model\n",
    "rmClassifer = RandomForestClassifier(labelCol=\"indexed\", \\\n",
    "                featuresCol=\"features_norm\")\n",
    "rmModel = rmClassifer.fit(trainingData)\n",
    "#Predict on the test data\n",
    "predictions = rmModel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features_norm\").collect()\n",
    "print(\"Results of Random Forest : \",evaluator.evaluate(predictions)  )\n",
    "\n",
    "#Create the Gradient Boost model\n",
    "gbt = GBTClassifier(labelCol=\"indexed\", featuresCol=\"features_norm\", maxIter=10)\n",
    "gbmmodel=gbt.fit(trainingData)\n",
    "#Predict on the test data\n",
    "predictions = gbmmodel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features_norm\").collect()\n",
    "print(\"Results of Gradient Boost : \",evaluator.evaluate(predictions)  )\n",
    "\n",
    "#Create the Logistic model\n",
    "lr = LogisticRegression(labelCol=\"indexed\", featuresCol=\"features_norm\")\n",
    "lrmodel=lr.fit(trainingData)\n",
    "#Predict on the test data\n",
    "predictions = lrmodel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features_norm\").collect()\n",
    "print(\"Results of Logistic regression : \",evaluator.evaluate(predictions)  )\n",
    "\n",
    "#Create the Linear SVM model\n",
    "lsvc = LinearSVC(labelCol=\"indexed\", featuresCol=\"features_norm\",maxIter=10, regParam=0.1)\n",
    "lsvcmodel=lsvc.fit(trainingData)\n",
    "#Predict on the test data\n",
    "predictions = lsvcmodel.transform(testData)\n",
    "predictions.select(\"prediction\",\"indexed\",\"label\",\"features_norm\").collect()\n",
    "print(\"Results of Linear SVC : \",evaluator.evaluate(predictions)  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
